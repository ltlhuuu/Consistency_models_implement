{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37e948f1",
   "metadata": {},
   "source": [
    "# Consistency Models Training Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441c90a7",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Consistency model are a new family of generative models that achieve high sample quality without adversarial training. They support fast one-step generation by design, while still allowing for few-step sampling to trade compute for sample quality. They also zero-shot data editing, like image inpainting, colorization, and super-resolution, without requiring  explicit training on these tasks.\n",
    "### Key Idea\n",
    "Learn a model that maps any arbitrary point in the latent space to the initial data point, i.e: if points lie on the same probability flow trajectory they are mapped to the same initial data point.\n",
    "### Contributions\n",
    "* Single step sampling\n",
    "* Zero-shot data editing: inpainting, outpainting e.t.c\n",
    "### Difinition\n",
    "Given a diffusion trajectory $x_{t\\in[t_{min},t_{max}]}$, we define a consistency function $f:(x_t,t)\\rightarrow x_{t_{min}}$.\n",
    "We can then train a consistency model $f_\\theta(\\cdot,\\cdot)$ to approximate the consistency function. A property of the consistency function is that $f:(x_{t_{min}},t_{min})\\rightarrow x_{t_{min}}$. To achieve this, we parameterize the consistency model using skip connections:\n",
    "$$\n",
    "f_\\theta(x_t,t) = c_{skip}(t)x_t+c_{out}F_\\theta(x_t,t),\n",
    "$$\n",
    "where $c_{skip}(t_{min})=1$ and $c_{out}(t_{min})=0$ and $F_\\theta(\\cdot, \\cdot)$ is the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ce0fc1",
   "metadata": {},
   "source": [
    "## Algorithms\n",
    "### Training\n",
    "To train the model we follow the following algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae20ac4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'iterations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_44240/1349929065.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mitr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# consider improved techniques for training consistency models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mimproved_CT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'iterations' is not defined"
     ]
    }
   ],
   "source": [
    "for itr in range(iterations):\n",
    "    data = data_distribution()\n",
    "    \n",
    "    # consider improved techniques for training consistency models\n",
    "    if improved_CT:\n",
    "        N = improved_timesteps_schedule(itr, iterations, initial_timesteps=10, final_timesteps=1280)\n",
    "    else:\n",
    "        N = timesteps_schedule(itr, iterations, initial_timesteps=2, final_timesteps=150)\n",
    "    \n",
    "    if adaptive_ema:\n",
    "        start_scales = 2.0\n",
    "        c = np.log(ema_decay) * start_scales\n",
    "        target_ema = np.exp(c / N)\n",
    "    \n",
    "    boundaries = kerras_boundaries(7, 0.002, N, 80).to(device)\n",
    "    sigma = boundaries\n",
    "    z = torch.randn_like(data)\n",
    "    \n",
    "    # consider improved techniques for training consistency models\n",
    "    if improved_CT:\n",
    "        # t = lognormal_timesteps_distribution(x.shape[0], boundaries, mean=-1.1, std=2.0)\n",
    "        mean = -1.1\n",
    "        std = 2.0\n",
    "        pdf = torch.erf((torch.log(sigma[1:]) - mean) / (std * math.sqrt(2))) - torch.erf((torch.log(sigma[:-1]) - mean) / (std * math.sqrt(2)))\n",
    "        pdf = pdf / pdf.sum()\n",
    "        t = torch.multinomial(pdf, num_samples, replacement=True)\n",
    "        t = t.view(-1,1).to(device)\n",
    "    else:\n",
    "        t = torch.randint(0, N - 1, (data.shape[0], 1), device=device)\n",
    "    \n",
    "    t_1 = sigma[t]\n",
    "    t_2 = sigma[t + 1]\n",
    "    \n",
    "    # consider improved techniques for training consistency models\n",
    "    if improved_CT:\n",
    "        teacher_model = None\n",
    "    else:\n",
    "        teacher_model = ema_actor\n",
    "    \n",
    "    loss = actor.loss(data, z, t_1, t_2, teacher_model)\n",
    "    mean_loss = loss.mean()\n",
    "    \n",
    "    if loss_ema is None:\n",
    "        loss_ema = mean_loss.item()\n",
    "    else:\n",
    "        loss_ema = 0.9 * loss_ema + 0.1 * mean_loss.item()\n",
    "    \n",
    "    actor_optimizer.zero_grad()\n",
    "    mean_loss.backward()\n",
    "    if grad_norm > 0:\n",
    "        actor_grad_norms = nn.utils.clip_grad_norm_(actor.parameters(), max_norm=grad_norm, norm_type=2)\n",
    "    actor_optimizer.step()\n",
    "    \n",
    "    # Step target network\n",
    "    for p, ema_p in zip(actor.parameters(), ema_actor.parameters()):\n",
    "        ema_p.mul_(target_ema).add_(p, alpha=1 - target_ema)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbec9058",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d36d834",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdedc1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TD3BC] *",
   "language": "python",
   "name": "conda-env-TD3BC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
